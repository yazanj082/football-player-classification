{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APDEiQrzyNJV"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import imantics\n",
        "from skimage.transform import resize\n",
        "import random\n",
        "from skimage import util\n",
        "import imgaug.augmenters as iaa\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.applications.vgg16 import VGG16 \n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import preprocess_input \n",
        "# clustering and dimension reduction\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "%matplotlib inline\n",
        "\n",
        "from colorama import Style, Fore\n",
        "blk = Style.BRIGHT + Fore.BLACK\n",
        "red = Style.BRIGHT + Fore.RED\n",
        "blu = Style.BRIGHT + Fore.BLUE\n",
        "res = Style.RESET_ALL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TkD83DgzpSl"
      },
      "outputs": [],
      "source": [
        "base_dir = ''\n",
        "annote_dir = 'archive/annotations/instances_default.json'\n",
        "images_dir = 'archive/images' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVriGyjFzteY"
      },
      "outputs": [],
      "source": [
        "images_listdir = os.listdir(images_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4LxO-z41paG"
      },
      "outputs": [],
      "source": [
        "image_size = 512\n",
        "input_image_size = (1920 , 1080)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82eDFhw11L6i"
      },
      "outputs": [],
      "source": [
        "def read_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (image_size, image_size))\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53NmhVXD_RQk"
      },
      "outputs": [],
      "source": [
        "def print_images(number,rows,cols,images_to_sample,mask=None):\n",
        "  random_numbers = [random.randint(0,len(images_to_sample)-1) for _ in range(number)]\n",
        "  fig, ax = plt.subplots(rows, cols, figsize = (12,8))\n",
        "  if mask is not None and len(mask) == len(images_to_sample):\n",
        "    for i, ax in enumerate(ax.flat):\n",
        "        if i < len(random_numbers):\n",
        "            ax.imshow(images_to_sample[i])\n",
        "            ax.imshow(mask[i], alpha=0.5)\n",
        "            ax.axis('off')\n",
        "  else:\n",
        "      for i, ax in enumerate(ax.flat):\n",
        "        if i < len(random_numbers):\n",
        "            ax.imshow(images_to_sample[i])\n",
        "            ax.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_images_with_text(number, rows, cols, images_to_sample, mask=None, texts=None):\n",
        "    random_numbers = [random.randint(0, len(images_to_sample)-1) for _ in range(number)]\n",
        "    fig, ax = plt.subplots(rows, cols, figsize=(12, 8))\n",
        "    \n",
        "    for i, ax in enumerate(ax.flat):\n",
        "        if i < len(random_numbers):\n",
        "            image = images_to_sample[random_numbers[i]]\n",
        "            ax.imshow(image)\n",
        "            ax.axis('off')\n",
        "            \n",
        "            if mask is not None and len(mask) == len(images_to_sample):\n",
        "                mask_image = mask[random_numbers[i]]\n",
        "                if mask_image.shape[:2] == image.shape[:2]:\n",
        "                    ax.imshow(mask_image, alpha=0.5)\n",
        "            \n",
        "            if texts is not None and len(texts) == len(images_to_sample):\n",
        "                ax.set_title(texts[random_numbers[i]], fontsize=12)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb_ZEW8I2cVu"
      },
      "outputs": [],
      "source": [
        "annote = json.load(open(annote_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u52rBySU2qxL"
      },
      "outputs": [],
      "source": [
        "id_to_images = {image['id']:image['file_name'] for image in annote['images']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boZqmTF02veT"
      },
      "outputs": [],
      "source": [
        "images = np.zeros((len(images_listdir), image_size, image_size, 3), dtype=np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "W9gxWOV62x7d",
        "outputId": "2b9fe7b0-4e9e-4988-f9f0-caf031d54086"
      },
      "outputs": [],
      "source": [
        "for image_id, image_filename in id_to_images.items():\n",
        "    cur_image = read_image(f\"{images_dir}/{image_filename}\")\n",
        "    images[image_id - 1] = cur_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ga4Gafp17hg"
      },
      "outputs": [],
      "source": [
        "print_images(9,3,3,images,None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38M6swa321IE"
      },
      "outputs": [],
      "source": [
        "masks = np.zeros((len(images_listdir), image_size, image_size, 1), dtype=bool)\n",
        "for annotation in annote[\"annotations\"]:\n",
        "    image_id = annotation[\"image_id\"]\n",
        "    segmentation = annotation[\"segmentation\"]\n",
        "\n",
        "    cur_mask = imantics.Polygons(segmentation).mask(*input_image_size).array\n",
        "    cur_mask = np.expand_dims(resize(cur_mask, (image_size, image_size), mode='constant', preserve_range=True), 2)\n",
        "\n",
        "    mask_index = image_id - 1\n",
        "    masks[mask_index] = masks[mask_index] | cur_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyJaKb4lJo0h"
      },
      "outputs": [],
      "source": [
        "print_images(9,3,3,masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciLN9Eyz3Zwy"
      },
      "outputs": [],
      "source": [
        "print_images(9,3,3,images,masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4A8EXTpZ6d7d"
      },
      "outputs": [],
      "source": [
        "def classify_status(stats,img):\n",
        "  result = []\n",
        "  for i in range(1, len(stats)):\n",
        "    # Get the bounding box coordinates of the component\n",
        "    x, y, w, h, area = stats[i]\n",
        "    x_axis,y_axis = [],[]\n",
        "    count = 0\n",
        "    for i in range(w):\n",
        "      x_axis.append(0)\n",
        "      for j in range(h):\n",
        "        if img[i,j] > 0:\n",
        "          x_axis[count] +=1\n",
        "    count = 0\n",
        "    for i in range(h):\n",
        "      y_axis.append(0)\n",
        "      for j in range(w):\n",
        "        if img[i,j] > 0:\n",
        "          y_axis[count] +=1\n",
        "      count +=1\n",
        "    x_axis = np.array(x_axis)\n",
        "    y_axis = np.array(y_axis)\n",
        "\n",
        "    ratio_std = (y_axis.std()/x_axis.std())\n",
        "    ratio = h/w\n",
        "    if ratio >= 8:\n",
        "      text = f\"standing\"\n",
        "    elif ratio<0.22:\n",
        "      text = f\"siting\"\n",
        "    else:\n",
        "      text = f\"crouching\"\n",
        "    result.append(text)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_mask(image,overlay):\n",
        "    overlay = cv2.cvtColor(overlay, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    masked_image = cv2.bitwise_and(image, overlay, overlay)\n",
        "    \n",
        "    return masked_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hn89Jj5uBDkv"
      },
      "outputs": [],
      "source": [
        "def extract_features(img):\n",
        "  hsv_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "# Extract Hue and Saturation components\n",
        "  hue = hsv_image[:,:,0].flatten()\n",
        "  saturation = hsv_image[:,:,1].flatten()\n",
        "\n",
        "  # Combine the color components into a single array\n",
        "  color_data = np.column_stack((hue, saturation))\n",
        "\n",
        "  # Reshape the color_data array to a single row with multiple columns\n",
        "  color_data_1d = color_data.reshape((1, -1))\n",
        "  # Convert pixel values to float\n",
        "  data = np.float32(color_data_1d)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beeLwgLxA24-"
      },
      "outputs": [],
      "source": [
        "def Build_teams_classifier(images,masks , test = None):\n",
        "\n",
        "  players = []\n",
        "  data = []\n",
        "\n",
        "  count_images = 0\n",
        "  for image in images:\n",
        "    img = image.copy()\n",
        "    mask = masks[count_images]\n",
        "    mask_result = []\n",
        "    result = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    thresh = mask[:,:,0]\n",
        "    count = 0\n",
        "  # Perform connected component analysis on the binary image\n",
        "    _, labels, stats, centroids = cv2.connectedComponentsWithStats(thresh.astype(np.uint8))\n",
        "\n",
        "    count = 0\n",
        "    # Loop through the connected components and extract the white regions\n",
        "    for i in range(1, len(stats)):\n",
        "      # Get the bounding box coordinates of the component\n",
        "      x, y, w, h, area = stats[i]\n",
        "      segment = np.full_like(mask, 0)\n",
        "      segment[y:y+h, x:x+w,:] = 255\n",
        "      mask_uint8 = mask.astype(np.uint8)\n",
        "      segment_uint8 = segment.astype(np.uint8)\n",
        "      overlay = (cv2.bitwise_and(mask_uint8,segment_uint8)*255).astype(np.uint8)\n",
        "      \n",
        "      img1 = apply_mask(img[y:y+h, x:x+w,:],overlay[y:y+h, x:x+w])\n",
        "\n",
        "      \n",
        "      img1 = cv2.resize(img1, (image_size, image_size))\n",
        "      players.append(img1)\n",
        "      feat = extract_features(img1)\n",
        "      data.append(feat)\n",
        "\n",
        "      count += 1\n",
        "    count_images += 1\n",
        "\n",
        "  features = np.vstack(data)\n",
        "\n",
        "  # cluster feature vectors\n",
        "  kmeans = KMeans(n_clusters=2)\n",
        "  kmeans.fit(features)\n",
        "  if test != None:\n",
        "    labels = kmeans.predict(extract_features(players[test]))\n",
        "    print(labels)\n",
        "    plt.imshow(players[test])\n",
        "    plt.show()\n",
        "  return kmeans,players\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvusccHwcAzb"
      },
      "outputs": [],
      "source": [
        "def classify_players(image,mask):\n",
        "  mask_result = []\n",
        "  result = image.astype(np.uint8)\n",
        "  thresh = mask[:,:,0]\n",
        "  players = []\n",
        "  # Perform connected component analysis on the binary image\n",
        "  _, labels, stats, centroids = cv2.connectedComponentsWithStats(thresh.astype(np.uint8))\n",
        "\n",
        "  count = 0\n",
        "  # Loop through the connected components and extract the white regions\n",
        "  for i in range(1, len(stats)):\n",
        "    # Get the bounding box coordinates of the component\n",
        "    x, y, w, h, area = stats[i]\n",
        "    segment = np.full_like(mask, 0)\n",
        "    segment[y:y+h, x:x+w,:] = 255\n",
        "    mask_uint8 = mask.astype(np.uint8)\n",
        "    segment_uint8 = segment.astype(np.uint8)\n",
        "    overlay = cv2.bitwise_and(mask_uint8,segment_uint8)\n",
        "\n",
        "    players.append(cv2.bitwise_and(result,overlay))\n",
        "    cv2.rectangle(result, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "    mask_result.append(overlay)\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 0.5\n",
        "    thickness = 1\n",
        "    text_size, _ = cv2.getTextSize(\"player\"+str(count), font, font_scale, thickness)\n",
        "    text_x = x + (w - text_size[0]) // 2\n",
        "    text_y = y - text_size[1] - 5\n",
        "    cv2.putText(result, \"player \"+str(count), (text_x, text_y), font, font_scale, (0, 0, 255), thickness)\n",
        "    count +=1\n",
        "\n",
        "  classify_status(stats,mask)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQgUXSUcdaXj"
      },
      "outputs": [],
      "source": [
        "model,players = Build_teams_classifier(images,masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkPWT69xtYRh"
      },
      "outputs": [],
      "source": [
        "texts = []\n",
        "for player in players:\n",
        "    feat = extract_features(player)\n",
        "    texts.append(model.predict(feat))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_images_with_text(16,4,4,players,texts=texts)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
